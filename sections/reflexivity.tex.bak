\chapter{Reflexive Measurement}\label{ch_reflexivity}

\section{Introduction}

Observer effects in the social sciences go by many names. It is not uncommon to speak of the `Hawthorne effect' \autocite{landsberger1958} or an `experimenter effect' \autocite{rosenthal1966} when the scientist or their science has a causal effect on its target of study. The idea that a measurement can causally affect the phenomenon it investigates is so widespread it is even enshrined in the common adage known as `Goodhart's Law'\footnote{`When a measure becomes a target, it ceases to be a good measure' \autocite{goodhart1984}.}. Observer-type effects turn out to be ubiquitous across the social sciences, recognized and explored by economists and psychologists alike \autocite{friedman1953,gergen1973}. Yet unified philosophical accounts of these diverse effects are rare despite their similar structure and widespread occurrence. For all that social scientists have labored long and hard to mitigate these problems in the course of their research, philosophers of science have neglected to put observer effects into broader philosophical perspective in a manner that can aid the practice of science. 

In philosophy of science, the related idea of a `self-fulfilling prophecy' is an ancient one, going back as far as the story of Oedipus, a mythical ancient Greek king whose best efforts to thwart an oracle's prophecy led to its tragic fulfillment. In its more modern guise philosophers of science have called the idea \textit{reflexive prediction} and its counterpart notion in the social sciences is commonly traced back to sociologist Robert K. Merton's \autocite*{merton1948} discussion of ``self-fulfilling science''. Like observer effects, this concept also captures the idea of the causal impact of science on what it studies. A canonical example of this phenomenon is a bank run: announcing an impending bank run may subsequently incite one. Contemporary philosophers of science have stressed the challenge reflexive prediction poses for theory development and testing in the social sciences (see \cite{kopec2011, lowe2018}). Despite a number of highly distinguished accounts of the idea of reflexive prediction over the past century, the animating idea of the causal effect of science on what it studies and the challenge that it poses is rarely married to a discussion of measurement.

This essay offers a novel account of the concept of \textit{reflexive measurement}. This account captures the salient features of diverse observer-type effects and recovers the intuition that a measurement is reflexive when agents are aware they are subjected to it. This is similar to the well-known idea of `measurement as intervention' in the philosophy of economics (e.g., \cite{morgan2001}). However, unlike existing versions of this account of measurement, a sensitivity to the different ways measurements causally affect their target of study necessitates revising the naive version of the measurement-as-intervention story. Measurements can sometimes fundamentally alter the phenomenon they investigate and other times only affect the data collected, leaving the underlying phenomenon unchanged. For example, in the context of survey research, it is common for respondents to lie about their preferences and opinions but the survey---the measurement instrument---does not causally affect the underlying phenomenon. This appreciation for the different ways measurements can causally affect the phenomenon they investigate sheds light on the deficiencies of the commonly used framework of de-biasing systematic measurement error for addressing the more fundamental problem of reflexive measurement.

% \footnote{Note, the concepts of \textit{performativity} and \textit{reactivity} are very similar and specific differences are discussed where appropriate. Since the point of departure for this work on measurement is the philosophical concept of reflexive prediction this account draws most heavily on those sources. A full discussion of the differences between these related concepts is beyond the scope of this paper.}

Behind the account of reflexive measurement presented here is a reconceptualization of reflexivity in science writ large. Existing philosophical accounts of reflexive prediction would be of considerable help in better understanding the causal effects of measurements on their targets of study were it not for the fact that these insights are specifically tied to an understanding of prediction and rarely given in any form of generality. Thus, it is necessary to step back from specific scientific practices (e.g., prediction, measurement, theorizing) and ascertain how science---broadly understood as a sociological phenomenon---interacts with what it studies. A clear pattern then emerges. The causal effects of science occur only when agents are aware of the science that investigates their behavior. This, in a nutshell, is reflexivity.

% The engagement with scientific literature beyond the traditional domains of economics and sociology paves the way for a potential solution to the problem of lying, misreporting, and withholding data---a common form of reflexive measurement across scientific domains. Drawing on insights from the mathematical and experimental psychologists \autocite{luce95,gergen1973}, designing a measurement to ensure truth-telling is beneficial for those studied yields measurements that are more reliable evidence for the underlying phenomenon. In some sense, in the face of reflexivity, measurements need to be made incentive-compatible or, as I refer to it below, measurements need to be \textit{reflexively optimal}. This idea also complements recent developments in theoretical computer science in the field of incentive-compatible learning and performative prediction \autocite{hardt2016,perdomo2020,cai2015}. The result of this engagement with psychology and computer science is that existing mathematical approaches to dealing with measurement are found to be inadequate. The commonly used framework of de-biasing systematic measurement error can be shown to be insufficient for addressing the more fundamental problem of reflexive measurement.

The essay is structured as follows. In Section \ref{sec_lit}, I review the major conceptual innovations on the topic of reflexive prediction by philosophers of science over the past century. Additionally, this review is supplemented by considerations of observer effects by experimental psychologists which are particularly germane to the topic of reflexive measurement. Section \ref{sec_character} collects these accounts and provides a general characterization of reflexivity in science. The central insight of this section is that agents' awareness of their position in a scientific study is the key causal pathway for reflexive effects. With a more general account of reflexivity in hand, the topic of measurement is then explored in Section \ref{sec_measurement}. Reflexive measurement is best captured by the measurement-as-intervention view, however, the naive understanding of this position requires modification in light of the distinction between data and phenomena. Section \ref{sec_conc} concludes and offers directions for future work.

\section{Literature Review}\label{sec_lit}

% \footnote{Since \autocite{mackinnon2006} primarily addresses the developments of reflexivity in economics and sociology it suffers from a lack of consideration of reflexivity concerns in empirical psychology, which I explicitly address below. Additionally, the related issue of performativity in computer science is missing from this account.}

The idea that science causally affects its target of investigation has been long discussed in both science and philosophy. In philosophy of science alone, it is known as `reflexivity', `performativity', and sometimes `reactivity'. However, this notion is mostly commonly discussed in the context of scientific theories and predictions. In this section, I provide a stylized overview of the conceptual development of this idea over the past century in order to subsequently develop an account of how measurements can casually affect what they measure. I draw from the well-developed concept of \textit{reflexive prediction} in philosophy of science and supplement this understanding with developments in contemporary science which explicitly concern tackling the problem of the causal effect of science on what it studies. For a more even treatment of the development of reflexivity, albeit with less focus on psychology and contemporary economics, see the historical overview of \autocite{mackinnon2006}.  

Mid-twentieth century philosophical accounts of reflexivity following the sociologist Robert K. Merton's \autocite*{merton1948} seminal account of `self-fulfilling science' are rare. Karl Popper \autocite*{popper1953} briefly discussed a general formulation of the idea in the context of historicism in philosophy of social science and Ernest Nagel \autocite*{nagel1961} also noted the challenge this posed for theory construction in the social sciences. Subsequent accounts in the 1960s and 1970s focused more narrowly on the causal role predictions in the social sciences have on shaping their own truth-conditions (e.g., \cite{buck1963, romanos1973}). These accounts focus heavily on the formulation and dissemination style of the prediction: whether the prediction was published in a newspaper or discussed on cable news, whether the prediction was public or private, etc. To different but ultimately similar degrees, these authors acknowledge that a single prediction will not, by itself, have a reflexive effect independent of how it comes to be known by those it makes predictions about. 

% \footnote{Kopec distinguishes between strong and weak predictions, where `strong' reflexive predictions are predictions that ``switch the truth-value of the prediction'' and `weak' reflexive predictions merely ``change the probability of the predicted event'' \autocite[p1252-3]{kopec2011}. Since the strong reflexive predictions are a subset of weak reflexive predictions, and the latter offers a substantive conceptual innovation over previous accounts, I consider only the latter here.}

These accounts from the 1960s and 1970s understood predictions in science as having a definite true/false truth value. A significant recent contribution by Kopec \autocite*{kopec2011} challenged this view, articulating a conception of probabilistic reflexive predictions. Here, a prediction is reflexive if it changes the probability of the event it predicts. The common use of applied statistics in developing predictions in the social sciences is better accommodated by this account. For example, social scientists have investigated whether public opinion polls indicating a favorite candidate in an upcoming election can increase that candidate's probability of winning \autocite{rothschild2014} and also whether the effects of election forecasts may depress voter turnout \autocite{westwood2020}. A narrow focus on the ultimate truth condition of the prediction misses the ways in which a prediction can nonetheless change individual behavior while leaving the resulting aggregate phenomena unchanged. Thus, even if a number of voters vote differently in light of public predictions, the overall result of an election may nonetheless remain unchanged.

A further criticism of existing philosophical work on reflexive prediction is that it fails to account of the idea that certain predictions may be more or less reflexive \autocite{lowe2018,cejka2022}. The ``Mertonian-derived, truth-centric notion of reflexive prediction'' \autocite[p10]{lowe2018} fails to capture the idea that, in some cases, the effect of a reflexive prediction on (even the probability of) an event is ``marginal at best'' \autocite[p8]{lowe2018}. If an impending bank run is announced on the front page of the newspaper of record it has a vastly different effect than on the front page of a local student newspaper. The shift in focus to degrees of reflexivity represents a welcome change in our philosophical understanding of the many ways scientific predictions can interact with the social world. 

Scientists have also developed their own accounts of reflexivity which are notably different from the philosophical views considered above. Contemporary work by economists on reflexivity has ``situate[d] the concept in recent thinking on complex adaptive systems'' \autocite[p331]{beinhocker2013}. This turn towards characterizing reflexivity in terms of systems-type thinking is associated with financier and investor George Soros, who has claimed that understanding the concept of reflexivity has enabled him to profit from his investments in financial markets (see, for example, \cite{soros2013}). On this account, reflexivity is a property of systems. The systems-account emphasizes the interactions between agents and their environment, as well as explicitly conceptualizing agents' goals and cognitive abilities. An upshot of this account is that it arranges different systems along a `spectrum of complexity' \autocite[p337]{beinhocker2013} and enables the comparison of physical, human, and artificial systems in terms of reflexivity and complexity---an unusual feature of accounts of reflexivity.

% \footnote{Experimenter effects also include the presence of implicit cues which can unconsciously influence study participants' behavior. I discuss this subtlety in more detail in Section \ref{sec_measurement}.}

Despite the common focus on reflexivity in economics by philosophers of science issues of reflexivity are found across many other sciences. It is helpful to also draw from the discipline of experimental psychology that has confronted reflexivity as a practical challenge. In doing so it becomes possible to develop a clearer overall picture of the causal effect of science on what it investigates. Phenomena like the `experimenter effect' \autocite{rosenthal1966} and `demand characteristics' \autocite{orne1962} have been well-known for decades and demonstrate the problems that come with either revealing information (e.g., a theoretical premise or expected result) to study participants during the course of research or participants `guessing' the aims and objectives of the study and then adjusting their behavior accordingly. The implications of these findings constitute ``a fundamental difference'' \autocite[p313]{gergen1973} between natural and social science.

Writing about the dangers of theories of psychology that are falsifiable ``at will'' by knowing study participants, mathematical psychologist R. Duncan Luce proposed the `non-oxymoron criterion' \autocite[p3]{luce95} for theory-testing: scientists should be confident that their experimental design allows the theory to be tested despite the subject's knowledge of the theory. In other words, psychological hypotheses should not be able to be confirmed (disconfirmed) by the study participant at will. Psychologists have differed in their recommendations for how to avoid this. On the one hand, considering only ``naive subjects'' ensures that study participants are uninformed and therefore theories can be tested in ``an uncontaminated way'' \autocite[p313]{gergen1973}. On the other hand, we can directly address the self-interest of the subjects such that it ``behooves the subjects to reveal their true preferences'' \autocite[p9]{luce95}. These views complement existing philosophical accounts by highlighting characteristics of study participants (e.g. how informed they are, their goals and desires) which contribute to the reflexivity of science.

% I will return to Luce's comments about study participants ``reveal[ing] their true preferences'' in more detail below. It is worth noting, however, that recent developments in theoretical computer science specifically address reflexivity concerns at the intersection of measurement and prediction by explicitly modeling self-interest when designing algorithms that learn from data. This literature on \textit{incentive-compatible learning}\footnote{This is also sometimes called \textit{strategic classification} \autocite{hardt2016} or \textit{incentive compatible estimation} \autocite{cai2015} or \textit{performative prediction} \autocite{perdomo2020}.} concerns eliciting accurate data when the source of the data has knowledge of the structure of the algorithm and its subsequent use. Examples of this kind of work include eliciting truthful information when people can strategically withhold data \autocite{krishnaswamy2021} and obtaining high-quality data when data collection is costly \autocite{cai2015}. I will cover in more detail the simpler case of \autocite{caragiannis2016}, who consider the classic problem of estimating the population mean of an unknown single-dimensional distribution where samples are supplied by strategic agents who wish to pull the estimate as close as possible to their own value. The approach of this line of work addresses reflexivity directly and attempts to mitigate its effects by explicitly modeling self-interest such it is beneficial to those studied to reveal their true preferences.

% \footnote{In the discipline of computer science reflexivity is commonly studied under the name of \textit{strategic classification} \autocite{hardt2016} or \textit{incentive compatible estimation} \autocite{cai2015} or \textit{performative prediction} \autocite{perdomo2020}.}

In conclusion, it is important to bear in mind that in addition to philosophy of science and economics, disciplines as diverse as psychology \autocite{luce95}, political science \autocite{rothschild2014,westwood2020}, complex systems \autocite{beinhocker2013}, and even theoretical computer science \autocite{hardt2016,perdomo2020} have all grappled with the issue that science causally effects its target of investigation in different forms. As I will detail below, observer effects are ubiquitous across scientific domains and only a broader understanding of these effects can do justice to the complexity of reflexivity in science. This literature surfaces some of the common concerns across these disciplines alongside tracking the development of reflexivity as a key idea in contemporary philosophy of science. The next section will tie together these concerns into a general characterization of the concept of reflexivity.








\section{Characterizing Reflexivity}\label{sec_character}

Since almost all explicit definitions of reflexivity are inextricably tied to prediction in this section I propose a characterization of reflexivity which applies to all scientific practices. As such, it will necessarily be broader in scope and include more of scientific practice than is common on other accounts. The proposed account is closer in spirit to earlier understandings of reflexivity which attempted to grapple with the ``complicated interaction between observer and observed'' \autocite[p14]{popper1953} at a high level of generality. Drawing from the approach of Grunberg \autocite*{grunberg1986}, the account proposed here sheds light on the causal pathway by which reflexive effects manifest themselves. This serves to fix ideas for the discussion of measurement in subsequent sections. Additionally, this account extends to non-social scientific domains; a feature of reflexivity that has been widely under-appreciated by those who insist the concept uniquely applies to the study of humans and human behavior.

The motivating question for this more general account is: which scientific practices might be reflexive? All conceptions of reflexivity considered in the preceding section implicitly rely on a view of science that encompasses the social interaction between `observer and observed' \autocite{popper1953} or `scientist and study participant'\autocite{gergen1973, luce95}. A broad view requires us to consider science as a sociological phenomenon and allow our characterization of reflexivity to include facts concerning how the science in question interacts with its target of study. Who the scientist is or what institution they work at can have an outsized impact on the results of a scientific study. This is, effectively, a more general formulation of the `formulation/dissemination-style' of reflexive predictions \autocite{romanos1973} which naturally extends to other scientific practices like measurement.

However, adopting broader sociological considerations is no small requirement. This means that irrespective of whether a specific scientific practice is known, the mere knowledge of the institution that carries it out can be sufficient to elicit a reflexive effect\footnote{There are even collateral effects from neighboring institutions or scientific practices. These are explored in the case of measurement in example \ref{ex_census}.}. Consider that when Google dropped its ``don't be evil'' motto \autocite{basu2015} users may have felt the need to change their behavior when interacting with Google's products. Even without knowing the specific scientific practices Google was carrying out to investigate their users' behaviors, this might---in the broad sense of being a social interaction between observer and observed---constitute an instance of reflexivity for Google's study of its own users.

This further entails that the private/public distinction that animates so much of the reflexive prediction literature is no longer helpful (e.g., \cite{buck1963,romanos1973,grunberg1986}). To see this consider the following example (adapted from \cite{grunberg1986}):

\begin{example}[Sumerian Economic Forecasts]
The current Chairman of US Federal Reserve Jerome Powell delivers the Federal Reserve's annual economic forecasts on national television in ancient Sumerian with a presentation in cuneiform characters.
\end{example}

\noindent Since, effectively, no one understands ancient Sumerian the forecast would be considered private. Setting aside the issue of market overreactions (e.g., \cite{debondt1985}), this would be an unprecedented action for a Chairman of the US Federal Reserve and may undermine investors' faith in the competence of major US financial institutions. This should constitute an instance of reflexivity in the same way that Google changing its motto should: the broader sociological context of a scientific practice can have enormous causal impacts on what it investigates.

The causal effect that science has on its target of study is clearly at the heart of all conceptions of reflexivity. On an overly simplistic view, reflexivity can even be understood as: the explicans causally affects the explicandum. Some kind of causal effect is clearly a necessary condition for the occurrence of reflexivity---on this, all philosophical accounts agree. But accounts of reflexivity differ in how they approach this. On one view, reflexivity is understood as a causal effect with a counterfactual component \autocite{romanos1973,buck1963}. Another view emphasizes the causal effect of reflexivity as a stochastic phenomenon. A reflexive prediction, for example, changes the probability of an event occurring \autocite{kopec2011} and can even be ascertained by a test of statistical significance \autocite{cejka2022}. A different kind of account gives definitions of reflexivity which omit causal language altogether in favor of clearly specifying the pathways along which the causal effects of reflexive science play out. Thus, for example, a reflexive prediction is ``an utterance... made public in a language in terms that can be understood by the agents to whose behavior it refers and who therefore can by their actions either falsify or fulfill it'' \autocite[p476]{grunberg1986}\footnote{Alternatively, ``in order to be reflexive it is sufficient for a public prediction to be partially believed'' \autocite[p484]{grunberg1986}.}. A distinct advantage of this final approach is that it subsumes the causal effects of science on what it studies by specifying the mechanism by which agents might come to frustrate or fulfill a scientific prediction.

Before offering my own version of this type of account of reflexivity, it is important to be clear about the nature of ``agents'' that constitute part of the phenomenon investigated by scientists. In my view, the systems account of reflexivity (e.g., \cite{beinhocker2013,soros2013}) correctly captures the important features of agency, including agents' goals, cognitive capacities, and actions within the scope of a definition of reflexive system\footnote{However, I do not believe the most promising path towards characterizing reflexivity is to ``situate the concept in recent thinking on complex adaptive systems'' \autocite[p331]{beinhocker2013}. Although there are undoubtedly good reasons to think about reflexivity in this manner for large-scale, complex phenomena like financial markets, the `systems' approach is ill-suited to capture small-scale scientific investigations like laboratory studies \autocite{luce95} and individual medical diagnoses \autocite{hacking1995}. Especially since some systems accounts of reflexivity (e.g., \cite[p332]{beinhocker2013}) require that all reflexive systems be complex systems.}. It is important to consider why this is particularly helpful. Firstly, note that reflexivity may characterize sciences that investigate collections of humans: organizations, governments, firms, etc., which act with a singular purpose. Secondly, it would be philosophically underwhelming to propose an account of reflexivity which rules out interesting cases like missiles \autocite{grunbaum1963} or thermostats \autocite{beinhocker2013} simply because the only agents to which the concept of reflexivity applies are human beings. It is desirable to simultaneously capture the intuition that there is something particularly philosophically interesting about the problems faced by social science but also that we should be open to discovering these problems in other scientific domains. Although there will certainly be disagreement over what constitutes agency, this ambiguity is a deliberate feature of the account presented here.

The account of reflexivity proposed here requires that the causal effect of observation or measurement or prediction---any form of scientific practice---on the target of inquiry be mediated through the awareness of the agents that constitute part of the phenomenon under investigation. Here, I am trying to generalize to all scientific practices the idea that the mechanism for a prediction to be reflexive is for it to be ``partially believed'' \autocite[above]{grunberg1986}. It is difficult to speak of ``belief'' in the context of measurement. Some minimal degree of awareness of being observed is the relevant necessary condition for reflexivity. This requirement widens the scope of what is to be considered reflexive, as did the move to include the broad sociological context of scientific practice beyond, for example, individual public predictions. What ultimately matters for reflexivity is not how a given prediction, theory, or measurement was published or disseminated but instead that the agents came to learn it. 

The implications of this novel understanding can be fully seen in the following example.

\begin{example}[Stoplight Example]
A researcher aims to measure traffic patterns at an intersection. They stand on the side of the road noting the presence and absence of cars waiting at a stoplight. Inadvertently, however, they keep stepping on the cable that powers the stoplight, affecting the frequency with which the stoplight changes color.
\end{example}

\noindent In this example, although the scientist causally intervenes in the target system they are seeking to study, the effect of this causal intervention is not a function of the agents' awareness of the science or scientist that studies their behavior. Thus, if the drivers of the cars (i.e., the agents) are unaware of the science that investigates their behavior, then the scientific study is not reflexive. This extends to the institution that the scientist is working for: if the agents are unaware not only of the scientist at the stoplight but of the broader sociological context in which they conduct their science, only then is science truly non-reflexive. As noted above, large corporations like Google and intelligence agencies like the CIA, which are often jokingly considered omniscient, will elicit reflexive effects even if the specific scientific investigations they carry out are unknown to those they study.

It is tempting to argue that awareness is also sufficient for reflexivity, however, I believe this kind of precise definition leads to the consideration of unhelpful counterexamples.

\begin{example}[Alien Social Science]\label{ex_aliens}
Assume only one species of aliens exists and consider that their alien social science which investigates human behavior on earth is entirely undetectable by us (i.e., has no causal impact we can discern). Despite this, some members of the public believe that aliens are real. Perhaps they have they have filled their imaginations with stories of Area 51 or watched too many \textit{X-Files} episodes. Thus, they adapt and change their behavior in ways they think might frustrate alien social science.
\end{example}

\noindent Since the account here argues in favor of considering collateral effects of institutions on earth (e.g., the FBI, Hollywood, etc.) a key part of reflexivity, then the alien social science is reflexive despite the lack of \textit{any} causal effect on the phenomena it investigates.

This surprising conclusion is a feature of the inclusion of collateral reflexive effects (from, say, neighboring scientific institutions with bad reputations as covered in example \ref{ex_census} below) in the proposed characterization of reflexivity. When coupled with awareness as the appropriate causal pathway for mediating reflexivity renders the range of cases to which the designation of reflexivity applies very broad. This is partly by design: the goal of this account is to extend existing ideas and intuitions about reflexivity to (potentially) cover all scientific practices. Even Ian Hacking's \autocite*{hacking1995} seminal account of the causal effects of scientific theories themselves cannot be included in a discussion of reflexive predictions without significantly changing the scope of the argument (and all the relevant definitions of reflexive prediction). Treating awareness as a sufficient condition for reflexive entails that a science can be reflexive without causally affecting its target of study, a conclusion completely at odds with the animating idea of the characterization given here.

The characterization of reflexivity proposed here entails that almost all social scientific practice is reflexive. This feature of my characterization of reflexivity might strike the reader as unwelcome. Yet narrowly defining reflexivity in terms of ``causal factors'' \autocite{romanos1973,buck1963} or ``changes in probability'' \autocite{kopec2011} to pick out particular instances of reflexivity lands philosophers of science in the awkward position of assuming the role of scientists: determining what is and isn't reflexive in virtue of measurable effects. Moreover, recent developments in how to think about reflexivity emphasizing that reflexivity is a matter of degree \autocite{lowe2018} lend support to the idea that even minimal reflexive effects are still worthy of inclusion in the definition of reflexivity.

Ultimately, if reflexivity is defined by its effects it lands us with an arbitrary delineation of the term. Consider that a definition using the language of ``causal factors'' and ``changes in probability'' entails that the same prediction uttered in two almost identical circumstances might nonetheless result in one being reflexive while the other is not. These differing circumstances could be different days of the week, neighboring geographic regions, or even just differ in as much as a single study participant. Even more problematic is the fact that the absence of a discernible reflexive effect does not indicate the absence of reflexivity. A public prediction might result in exactly the same pattern of behavior (or probability of its occurrence) but the motivations for carrying out the behavior may have completely changed as a result of the prediction. A focus on the causal pathway by which reflexivity manifests allows philosophers of science to sidestep issues with ascertaining whether there is an appropriately reflexive causal effect for a given scientific practice. 

Thankfully, social scientists are increasingly aware of the reflexive effects of their science. Contrary to earlier philosophical accounts of reflexivity which could only find a ``a great deal of anecdotal evidence'' \autocite[p487]{grunberg1986} for the existence of reflexive predictions, a serious effort has been made to investigate the effects of public predictions in areas like election forecasting. Well-known election forecasts in the United States like Nate Silver's 538 website\footnote{\url{https://fivethirtyeight.com}} which get national press coverage are now being investigated for their effects in depressing voter turnout \autocite{westwood2020}. Additionally, opinion polls indicating a favorite candidate in an upcoming election can increase the probability of that candidate winning \autocite{rothschild2014}. The advantage of taking seriously the recommendation to treat reflexive effects as varying by degree \autocite{lowe2018} is that it leaves open the possibility of acknowledging that almost all social science is reflexive, though much of it might have barely any effect at all. Philosophers can offer a clear account of reflexivity and let scientists determine where it is appropriate to worry about it.

In summary: I provided a sociological picture of scientific practice, whereby a reflexive scientific practice can causally affect its target of inquiry when the cause is mediated through the agents' awareness. Although this condition is necessary for reflexivity, and, indeed, it is often sufficient, a definition should be avoided: it adds little to our scientific and philosophical understanding of a wide-ranging, complex phenomenon and only serves to distract us with far-fetched counterexamples. Furthermore, it is important not to define reflexivity by its effects. Today's election forecasts are reflexive, as are tomorrow's---irrespective of whether one elicits a causal effect and the other does not. What matters is whether the agents that comprise the phenomenon under investigation are aware of the prediction (and so it goes for measurement, etc). Philosophers of science should let scientists determine the effects of reflexivity; our role is to clarify the phenomenon of reflexivity as one that does or does not apply to various scientific practices and domains. However, before instantiating this account in the novel context of measurement, it is important to consider the implications of this view for what kinds of science are reflexive.




% \section{Reflexivity \& Social Science}\label{sec_social_science}

% An upshot of the preceding section is that it engenders a reconsideration of the claim that reflexivity is exclusively a property of the social sciences and therefore can be used as a demarcation criterion between scientific domains. It has been commonly asserted by philosophers (e.g., \cite{buck1963,popper1953}) that reflexivity (in some form) ``is a phenomenon proper to the social sciences'' \autocite[p484]{grunberg1986}. Against this position, some have argued that feedback systems like missiles should be considered reflexive \autocite{grunbaum1956,grunbaum1963}. Contemporary research has eschewed debates about demarcation (e.g., \cite{lowe2018,kopec2011,cejka2022}), however, the use of reflexivity as a demarcation criterion between scientific domains remains undisputed. I do not wish to challenge the intuition that the study of living human beings and their behavior presents challenges not found when studying stars or atoms. This intuition strikes me as entirely correct. However, the characterization of the preceding section offers a means of reconciling this intuition with a more nuanced understanding of where reflexivity does and does not apply, ultimately entailing a rejection of it as a phenomenon ``proper'' to the social sciences.

% It is never entirely clarified what is meant by ``social science'' throughout these arguments. Clearly, disciplines like economics, political science, and sociology are all included. On the side of ``natural science'', presumably, we have subjects like physics, chemistry, and biology. Through these (and a few other) examples, this division of scientific domains effectively takes place at the level of academic departments. This is regrettable for two reasons. First, reflexivity does not apply uniformly within even a single social science and, secondly, interdisciplinary subjects like cognitive science are left out entirely.

% Before considering the possibility of reflexive natural science, it is helpful to briefly dwell on the nature of agency alluded to in the preceding section. The picture of agency I'm relying on in my account of reflexivity is drawn from those who approach the study of reflexivity using the framework of complex systems (e.g., \cite{beinhocker2013,soros2013}). These accounts rely on a system-level description of phenomena (like financial markets) which includes agents with goals, available actions, variable cognitive functions, and even ``internal models'' of how their actions yield consequences \autocite[p331]{beinhocker2013}. My account stressed agents' awareness but eschewed the stronger criterion of ``understanding'' is used in some accounts of reflexive prediction (e.g. \cite{grunberg1986}). My aim is to capture the idea of an observer effect in its broadest possible formulation. Reflexivity also requires agents---in some form or other---to be part of the phenomenon under investigation. I think it uncontroversial to say the study of stars and atoms can never be reflexive: these phenomena are simply not agents in any relevant sense of the word. Thus, the proposed account of reflexivity in some sense `lines up' with the intuition that much of the social sciences are reflexive whereas much of the natural sciences are not.

% However, we must not be too quick to jump to conclusions about the natural sciences; without a closer consideration of entities that meet the standards for agency, we should not conclude that natural sciences are entirely non-reflexive. Most notably, I think one scientific domain that most certainly meets the criteria for reflexivity is ecology: in particular the study of primates. Primates are most certainly aware of being observed. There is evidence of observer effects when studying Capuchin monkeys \autocite{metcalfe2022} and there is even evidence it can be mitigated by habituation \autocite{crofoot2010}. The study of primates presents an excellent case for reflexivity: they have different goals, levels of awareness, and cognitive faculties than humans, and thus reflexivity entails entirely different behaviors than, say, humans reacting to election forecasts. Thus, it is possible to see the study of the natural world and the social world along a continuum where it is the differences in the types of agents studied and the causal interactions between scientists and their target of study that make for differences in the reflexivity of science.

% As alluded to above, fields like cognitive science and artificial intelligence might include reflexive scientific practices. Ultimately, the inclusion of fields like these in the category of reflexive sciences hinges on the appropriate definition of agency and awareness. Counterexamples like missiles \autocite{grunbaum1956,grunbaum1963} and thermostats \autocite{beinhocker2013} to definitions of reflexivity which entail that only social scientific domains are reflexive prompt interesting questions about the nature of agency and its relation to awareness of scientific practices. These counterexamples are clear instances of causal feedback loops: they are self-correcting in the sense that once a goal is specified, these systems will take actions to change their environment to satisfy the goal\footnote{Furthermore, these kinds of systems may soon represent some form of scientific practice: the growth of automation in science means that in the not-too-distant future, it is entirely plausible that major policy decisions may be taken autonomously (e.g., \cite{zheng2022})}. Doing justice to all potential counterarguments involves giving a comprehensive account of agency (and also awareness), which is beyond the scope of this paper. However, my goal here is to bring to the reader's attention that the broad formulation of reflexivity in terms of agents' awareness encompasses scientific domains of study beyond the social sciences. 

% The goal of this section was to argue that the traditional conception of reflexivity as only applicable to the social sciences is incorrect and ultimately misguided. If the age-old division between ``social'' and ``natural''  science is based on the reflexivity of one (but not the other) then this understanding of the division reflects anachronistic thinking. Natural scientific domains like ecology are clearly reflexive. Furthermore, as the previous examples of thermostats and missiles show, reflexivity hinges on a definition of agency and what it means for agents to be ``aware'' of scientific practices. Ultimately, the framework developed here to better understand reflexivity allows us to extend considerations of the causal feedback effects of science to entirely new domains and forms of scientific practice.




\section{Reflexive Measurement}\label{sec_measurement}

% \footnote{I make the minimal assumption that measurement requires data collection and focus on this aspect of measurement throughout this section. This aspect of measurement is common to all philosophical accounts of measurement I have been able to find. Additionally, this understanding of measurement remains neutral with respect to questions on operationalism and conventionalism, realism and measurement, model-based accounts of measurement, etc (see \cite{sep-measurement-science} for an extended discussion of philosophical accounts of measurement in science).}

Despite the enormous amounts of ink spilled by scientists lamenting the challenges of collecting accurate data from study participants in laboratories and surveys, this aspect of scientific practice has been mostly overlooked by philosophers of science working on reflexivity. In this section, I instantiate the concept of reflexivity in the context of scientific measurement. Note, however, no new philosophical account of measurement is given in this section. Instead, the discussion of measurement sits closer to how a scientist encounters it. The focus of this section is on data collection since no measurement is possible without it. The heuristics to which scientists avail themselves to understand observer effects are exactly the level at which this account is pitched: it is an attempt to unify these solutions under a single philosophical perspective.

% \footnote{Note, whether or not the following observer-type effects are general and to what extent they replicate is an active area of research in every scientific domain that discovers any hint of these effects. However, consideration of these effects is considered standard practice in `good study design' across scientific fields, so much so that they are commonly found in textbooks across the social sciences (see, for example, \cite{groves2011,stantcheva2022,goodwin2009}).}

It is worth beginning with what is known about observer effects by scientists working across different fields. In its most general formulation across the social sciences, this is known as the `Hawthorne effect' (see \cite{landsberger1958}) or `experimenter effect'\footnote{Though experimenter effects occur when study participants are not explicitly aware of them (e.g., through implicit cues that are registered subconsciously) the focus of this section is the reflexive effects of measurement. As per the characterization in the preceding section, these are only the effects that participants are aware of.} \autocite{rosenthal1966}, where humans react to being observed and change their behavior in light of this observation. This general effect has been given a myriad of more specific formulations in different circumstances. To name a few of the most common found in scientific experiments: `demand characteristics' are a phenomenon where study participants in an experiment act in ways they think the scientist desires \autocite{orne1962}; the `Pygmalion effect' is a psychological phenomenon whereby high expectations lead to improved performance \autocite{rosenthal1968}; the `John Henry effect' concerns the actions that study participants take on learning they are placed in a control group (as opposed to a treatment group) to overcome the disadvantage of being an experimental control \autocite[p399]{dictionary_psych}. Outside of experiments, observer effects are commonly found in applied survey research: `priming' occurs when a survey asks leading questions which can skew survey responses \autocite[\S 6.2]{stantcheva2022}; additionally, `social desirability bias' is the phenomenon of surveys respondent lying or not sharing sensitive opinions  \autocite{krumpal2013}. Even `Goodhart's Law' has its origins in the challenges faced by economists measuring economic indicators to set monetary policy \autocite{goodhart1984}.

These disparate concerns all have the same root: the causal effects of scientists and their science on the target of study. Crucially, the kind of effects cataloged above are all mediated through the awareness of the agents studied. Study participants in laboratory experiments and respondents taking surveys are all fully aware of their role in scientific studies. Indeed, this is required for ethics approval. Thus, reflexive measurement can best be understood as the idea of `measurement as intervention', which has long been known in philosophy of economics. Writing about the role of measurement instruments in economics, Mary Morgan shrewdly writes:
\begin{quote}     
    ``The ways in which the economic body is investigated and data are collected, categorized, analyzed, reduced, and reassembled amount to a set of experimental interventions---not in the economic process itself, but rather in the information collected from that process.`` \autocite[p237]{morgan2001}
\end{quote}
\noindent However, Morgan contends that the interventions do not causally affect the ``economic process itself'' and instead affect the ``information collected from that process''. In the context of much of contemporary economics, this seems apt, however, more broadly this account fails in other settings\footnote{See Example \ref{ex_spe}. I explore this in more detail below.}. This insightful intuition about measurement instruments can be better appreciated by further considering the difference between `data` and `phenomena'.

% \footnote{Contemporary philosophical work on reactivity in similar contexts of measurement (e.g., \cite{runhardt2023}) draws on a conception of reactivity developed by \autocite{golembiewski1976} which is an exemplar of this first type of reflexive measurement: a measurement which causally affects the underlying phenomenon.\label{fn_reactivity}}

A helpful philosophical account of the difference between data and phenomenon was developed by Jim Woodward \autocite*{woodward1989}. Phenomena are ``relatively stable and general features of the world which are potential objects of explanation and prediction by general theory'', whereas data ``by contrast, play the role of evidence for claims about phenomena'' \autocite[p393-4]{woodward1989}. What matters in any scientific description or analysis of a phenomenon is that ``the data should be \textit{reliable evidence} for the phenomena in question'' \autocite[p398, emphasis original]{woodward1989}. Furthermore,
\begin{quote}
  ``Scientific investigation is typically carried on in a noisy environment; an environment in which the data we confront reflect the operation of many different causal factors, a number of which are due to the local, idiosyncratic features of the instruments we employ (including our senses) or the particular background situation in which we find ourselves.'' \autocite[p398]{woodward1989}
\end{quote}
\noindent In the context of the account of reflexive measurement introduced above (i.e., `measurement as intervention'), data reflect the operation of measurement instruments and the broader sociological context in which scientists administer their measurement. Crucially, however, the causal effect of the measurement on what is being measured might affect the underlying phenomena itself and/or the data collected about it. To see this more clearly, I now consider two concrete examples.

To make vivid how an act of measurement may cause the phenomena under investigation to change, consider the following well-known experiment by psychologist Philip Zimbardo:

\begin{example}[Stanford Prison Experiment]\label{ex_spe}
In 1971 a psychologist recruited participants for a ``psychological study of prison life'', which was a planned one-to-two week experiment that simulated prison life (see \cite[\S 2]{spe} for details). The goal was to assess the psychological effects of becoming a prisoner or prison guard.
\end{example}

\noindent A full account of the Stanford Prison Experiment can be found in \autocite{zimbardo2008}. It was prematurely ended after only 5 days since ``prisoners were withdrawing and behaving in pathological ways, and... some of the guards were behaving sadistically'' \autocite[\S 8]{spe}. The ethics of this kind of experiment have been questioned: participants who simulated prisoners were deliberately made to feel humiliated \autocite[\S 3]{spe}. Zimbardo's method of investigating the effects of simulated prisoner-guard has also been criticized as poor scientific practice \autocite{letexier2019}. Ultimately, it is abundantly clear that if the effects of the experiment are so pronounced as to induce a study participant to ``[break] down and began to cry hysterically'' \autocite[\S 8]{spe} then the measurement is reflexive in the sense of causally affecting the underlying phenomenon.

In contrast, a reflexive measurement can causally affect the data collected by a scientist without altering the underlying phenomenon under investigation. This is common in almost all forms of survey research where participants have the opportunity to lie or misrepresent their opinions. Here, a sensitive issue like the approval of a controversial political figure may be unaffected by a reflexive measurement but the data collected may be influenced by the study participants' reluctance to truthfully report their views. I believe this is the most promising way to realize Mary Morgan's \autocite*{morgan2001} insight that measurements of the economy are interventions ``in the information collected from that process''. 

The next example provides a concrete case where the social context of the scientific practice can create exactly this kind of effect.

\begin{example}[2020 US Census]\label{ex_census}
    In the run-up to the 2020 US Census, then-President of the United States Donald Trump made repeated remarks about the possibility of adding a citizenship question to the census (see \cite{blake2022}). Subsequently, the Hispanic response rate was more than three times lower on the 2020 census than on the 2010 census\footnote{See Appendix 1 for calculation of this figure.}.
\end{example}

% \footnote{\color{red}TODO ``The general tendency in “do not know” responses increased proportionally to the sensitivity of the issue.'' \autocite{dadabaev2007}.}

\noindent This example highlights an important and often overlooked facet of scientific practice: \textit{who} the scientist is or \textit{what} institution they represent can have direct consequences on their ability to investigate phenomena in the face of reflexivity. Here, explicit condemnation of undocumented immigrants by former president Donald Trump may have had a causal role in more than tripling the number of those of Hispanic origin in the US who didn't complete the 2020 census compared to 2010\footnote{It is possible these numbers reflect a possible confound: the presence of the covid-19 virus. In this instance, the hispanic non-response rate increased more than for other subgroups. This example also admits a hypothetical interpretation. It illustrates a possible causal pathway by which reflexivity affects a measurement outcome.}. The underlying phenomena of interest investigated by the census (e.g., respondent's age, gender, income, etc.) don't change but the data collected are influenced by a powerful leader with the ability to use census data to create policies that leave undocumented immigrants worse off by deporting them.

% The sociological picture of science presented in the previous section which focuses on scientific practice is central to the view of reflexive measurement proposed here. Institutions, people, expectations, etc all matter in changing the calculus of costs and benefits that study participants carry out when providing data. Though measurements can alter an underlying phenomenon (as in the Stanford Prison Experiment example above) this is often considered poor research design and scientists typically seek to eliminate these effects insofar as they are able to. Mitigating reflexive measurement effects on the data is a more difficult proposition that requires reasoning about agents' goals and cognitive abilities. Given the challenges associated with overcoming this latter kind of reflexive measurement issue, I now turn to concrete proposals from across scientific domains developed specifically to collect data that are more ``reliable evidence'' for the phenomenon in question.

% \section{A Concrete Proposal}\label{sec_proposal}

% Measurement without care on behalf of scientists to mitigate observer-type effects on data collection---even if the underlying phenomenon is unchanged---will result in data that are not reliable evidence for the phenomenon in question. The resulting inferences and predictions will be artifacts of the measurement rather than accurately represent the phenomenon under investigation. I believe the solution to problems of reflexive measurement lies in developing a scientific understanding of how our measurements affect the incentive structures of the agents we collect data about. The rest of this section collects and synthesizes disparate observations from scientists dealing with observer effects to motivate a concrete approach for modeling the reflexive causal effects of measurement instruments.

We can be clearer about the particular phenomenon of reflexive measurement where a measurement casually affects either the data collected or the underlying phenomenon. The change in the distribution of the sample resulting from a reflexive measurement can be thought of as a kind of \textit{distribution shift}\footnote{This language is commonly used in computer science in the related context of \textit{performative prediction} \autocite{perdomo2020}.}. The distribution shift of the sample represents its departure from the population-level data model. The measurement itself is an intervention that, for example, affects study participants' willingness to lie or conceal information in the face of a prying scientist. Notice this intervention only affects the sample since it is only the sample that is subjected to the measurement. Thus, this kind of reflexive measurement can be thought of as a kind of distribution shift where the sample distribution no longer represents the population distribution. 

By way of contrast to this understanding of reflexive measurement, it is helpful to consider the commonly used approach of `de-biasing' systematic measurement error. The systematic component of measurement error always occurs, with the same value, when the instrument is used in the same way in the same case (see \cite{tal2019}). Thus, for example, we might say the systematic component of measurement error for a poorly worded survey question on political attitudes occurs when the responses are, for example, `X\% more left/right-leaning'.

\begin{example}[De-biasing measurement error]\label{ex_debias}
Consider the case of a survey question asking about presidential approval in the US, which was answered by $N$ respondents. The data $X_1, \dots, X_N$ are assumed to come from a Gaussian distribution with unknown mean $\mu$ and variance $\sigma$. A scientist might then want to learn the value of $\mu$. The statistical error associated with each random variable $X_i$ is decomposed into a random and systematic component:

\begin{equation*}
    \epsilon_i = \epsilon_i^{\text{random}} + \epsilon^{\text{systematic}} =  \mu - X_i
\end{equation*}

\noindent Given further knowledge of the particulars of this domain of social inquiry, the scientist might impose additional assumptions about, for example, the shape of the distribution of the errors, or their covariance structure. These assumptions capture some of the flaws associated with a particular measurement instrument or measurement process. Ultimately, a scientist could make a post hoc correction for measurement error by subtracting off (often called `de-biasing') the systematic component of the error:

\begin{equation*}
    X_i^{\text{new}} = X_i + \epsilon^{\text{systematic}}
\end{equation*}

\noindent Which will provide a more accurate (i.e., less biased) estimate of $\mu$.
\end{example}

This example is paradigmatic of how measurement error is handled in the social sciences. The measurement instrument is biased and assumed to interact with those it's intended to measure in a uniform manner. The post hoc measurement error correction\footnote{Since $\epsilon^{\text{systematic}}$ is unknown a correction is only possible with an estimate of this quantity. Ascertaining whether or not this estimate is unbiased with respect to reflexive measurement effects is non-trivial. For a related discussion of this problem in the context of reflexive prediction see \autocite{cejka2022}.} can be read as, effectively, claiming the underlying data generating process measured by the instrument is actually a Gaussian distribution with mean $\mu - \epsilon^{\text{systematic}}$ and variance $\sigma$ once the causal effect of the instrument on the data generating process is accounted for.

However, this kind of correction presumes the underlying sample distribution remains unchanged in the face of reflexivity except for a difference in means. In many settings, this may be a reasonable and accurate assumption. However, this framework of de-biasing error cannot account for changes in the higher moments (e.g., variance, skew, etc.) of the underlying distribution. Moreover, the type of statistical distribution itself might change, often considerably, as a result of the measurement. In example \ref{ex_census} above, some Hispanic subgroups who felt threatened by the increased condemnation of undocumented immigrants might be entirely missing from the resulting data. The problem of reflexive measurement is a deeper one than the framework of measurement error allows. This understanding of reflexivity and measurement error also applies more generally to de-biasing corrections in reflexive prediction \autocite{cejka2022}. Sometimes these are appropriate responses to the problem of reflexivity in measurement, however, they are not a substitute for a general understanding of the problem of distribution shift induced by a measurement.




\section{Distribution Shift and Mechanism Design}\label{sec_reflex_mechdes}

How best then to correct the sample distribution shift that results from a measurement? I think it is instructive to return to the observation by psychologist R. Duncan Luce who, when he advocated the `non-oxymoron criterion' for theory-testing discussed above, noted that studies should be designed such that it ``behooves the subjects to reveal their true preferences'' \autocite[p9]{luce95}. The account of reflexivity in the previous section focused on the causal pathway of agents' awareness, coupled with their goals, cognitive capabilities, and the actions available to them. Explicit concern with what agents want facilitates the possibility of designing measurements that induce a distribution shift such that accurate data are collected because it is in the study respondent's best interests.

Thus, we can think about whether measurements are, in a loose sense, incentive-compatible\footnote{This has a specific, technical meaning in the context of mechanism design. Here, I use it in the informal sense.}. Incentive-compatible measurements induce minimal distribution shift such that the data collected are reliable evidence for the underlying phenomenon. This idea is related to that of \textit{performative optimality} developed in Perdomo et al. \autocite*{perdomo2020} to capture the distribution shift caused by performative predictions\footnote{Their proposed definition is one of iterative convergence from model retraining \autocite[Definition 2.3]{perdomo2020}. The use of the word `prediction' should not confuse philosophers: the problem they consider is simultaneously a problem of measurement. Data are collected for retraining after each iteration of the model is deployed.}. Two differences being: the account here presupposes neither a model nor some form of model retraining. A single measurement (a survey, a laboratory experiment, etc) should be designed in such a way as to be \textit{reflexively optimal}. It should induce a distribution that is reliable evidence for the phenomenon under investigation (i.e., the sample distribution should be an accurate representation of the population distribution). Thus, it should incentivize truth-telling, discourage withholding relevant information, etc.

Further departing from Perdomo et al. \autocite*{perdomo2020}, it is helpful to consider reflexive optimality an equilibrium notion\footnote{The equilibrium notion of \autocite[p1]{perdomo2020} ``coincide[s] with the stable points of $[\text{model}]$ retraining'' and does not reflect an understanding of why agents act they way they do. In contrast, recent work \autocite{oesterheld23} conceives of a truth-telling equilibrium in a performative prediction game as one induced by the self-interest of the participants. In the author's view, this latter contribution is the more promising approach to tackling the problem of reflexive measurement.} in the game-theoretic sense (e.g. \cite{nash1950}). This is helpful for two reasons. First, it allows scientists to give an explicit model of agents' motivations and reasoning and how they interact with a measurement. As argued above, this is a key facet of understanding how reflexive science causally affects its target of study. Secondly, it facilitates the application of the techniques of mechanism design to the problem of designing reflexively optimal measurement instruments. This turns out to be closely related to an active area of research in theoretical computer science called \textit{incentive-compatible learning}. Here, the choice of statistical estimator or algorithm itself can induce people to adapt their behavior. Thus, it is possible to re-frame the choice of estimator or algorithm as one that induces truth-telling on behalf of those data are collected from. To better understand this approach, consider the following example from Caragiannis et al. \autocite*{caragiannis2016}:

\begin{example}[Incentive-Compatible Mean Estimation]\label{ic_estimators}
A statistician is trying to estimate the mean preferred temperature of occupants of a building. A sample of occupants are randomly selected and asked their preferred temperature. Consider the following scenarios.

In one case, each person sampled is told that the estimator the statistician will use for their estimate of the population mean is the sample mean. Notice that if you have a preference for, say, warmer temperatures, you are best off lying about your preferred temperature to raise the sample average. This is because more extreme values will raise the sample average.

Suppose the statistician instead uses the sample median as his estimate of the population mean and this is communicated to each person in the sample. Even if you have a preference for much warmer temperatures, you no longer gain by lying since the median is robust to large outlier values (see \cite{caragiannis2016} for extended discussion of this result).
\end{example}

In example \ref{ic_estimators} above, there is an explicit model of the relationship between the statistical estimator and the data collected in terms of benefits to people (i.e., their utility). The choice of statistical estimator (i.e., measurement instrument) is recast as a game theoretic problem whereby the statistician and the people in the sample play a game. The statistician wants to estimate the population mean. People in the sample will report their preferred temperature truthfully if they stand to benefit from it or can't benefit from lying. Thus, the statistician can use the \textit{sample median} to estimate the \textit{population mean} to achieve reflexive optimality. Note that despite the game-theoretic formulation of the problem the goal of statistical inference remains the same.

In this example, the sample distribution changes as a function of the estimator yet the underlying phenomenon of interest (people's preferred temperature) remains unchanged throughout. The measurement instrument (i.e., estimator) is chosen so as to induce a distribution shift which is more reliable evidence for people's preferred temperature. This framework of incentive-compatible estimators and algorithms has been extended to explicitly causal settings \autocite{toulis2015}, forecasting problems \autocite{roughgarden2017}, bandit-type exploration algorithms \autocite{mansour2019}, survey design \autocite{roth2012surveys}, and even drug approval protocols \autocite{bates2022}. It often makes the strong assumption that study participants know the functional form of the estimator and possess an ability to reason about how the actions they can take ultimately affect their welfare. However, it explicitly models the incentive structures faced by agents whose behavior is measured. This captures the key idea of the proposal that opened the section: scientists need to understand how their measurements affect the incentives of agents they collect data about.





\section{Conclusion}\label{sec_conc}

I have argued for a novel conception of reflexivity that puts the sociological practice of science at the center of our understanding of reflexivity. This move facilitates the consideration of the multitude of ways science and scientists causally affect their target of study. Reflexivity concerns a kind of causal effect that science has on its target of study where agents that comprise the phenomenon of interest are aware of the scrutiny they are subjected to. In the case of measurement, we can distinguish this measurement-as-intervention view by virtue of whether the measurement causally affects the underlying phenomenon or the data collected about it. The correct understanding of reflexive measurement is given by the concept of distribution shift, where the sample distribution is no longer an accurate representation of the population model due to the causal effect of the measurement.

A few points are worth emphasizing. Firstly, scientists who warn of the consequences of observer effects or self-fulfilling science often do not narrowly focus on either measurement or prediction but instead explore and investigate cases where they co-occur. In psychology, researchers \autocite{gergen1973,luce95} consider how revealing a theoretical finding during a laboratory experiment can result in the study participants falsifying (or confirming) the experiment at will. In computer science, researchers have considered the effects of predictions on subsequent data collection \autocite{perdomo2020}. The account presented here offers a more general characterization of reflexivity which is more faithful to its varied manifestations. In my view, large swathes of science are entirely reflexive and yet, perhaps surprisingly, reflexive effects are often quite minor. Thankfully, scientists are increasingly aware of this phenomenon and have begun investigating specific occurrences of reflexivity in a far more thorough capacity than philosophers (e.g., \cite{rothschild2014,westwood2020}).

Additionally, an upshot of the characterization given in Section \ref{sec_character} is that the terrain of the discussion concerning the presence of reflexivity, reactivity, and performativity in a scientific domain should shift from an antiquated ``social'' versus ``natural'' science framing to one instead marked by a deeper appreciation for the nature of agency. The question `is a science reflexive?' is transformed into `what is the nature of agency?' in virtue of the concern with awareness as the causal pathway along which reflexive effects materialize. Where opinions differ on the nature of agency, so too will they differ on the designations of reflexivity. Counterexamples to purely social scientific definitions of reflexivity like missiles \autocite{grunbaum1956} and thermostats \autocite{beinhocker2013} make this point abundantly clear. In my view, this is a welcome change. It moves from treating an existing academic division of labor as a primordial categorization of scientific practice to one instead informed by careful study of differing targets of inquiry.

Two extensions to the line of research initiated here are clear. Firstly, it is worth noting a significant omission from the present account is that of qualitative social science. Qualitative research techniques across the social sciences have become increasingly sophisticated (see, for example, \cite{king2021}). Further research outlining how the account presented here interacts with scientific practices like structured interviews and ethnographic research would be welcome. Secondly, it is an interesting and challenging proposition to extend the understanding of reflexive measurement as distribution shift to scientific practices like prediction and theory development. As introduced here, the concept is bound up with data collection, and extending the account here for other scientific practices may yield insights that aid scientists in overcoming the reflexive effects of science.

Almost half a century ago, political scientist Christopher Achen lamented the lack of understanding social scientists possess concerning how their measurement instruments investigate the world. He wrote:

\begin{quote}
``[m]ajor improvements in our understanding of political thinking may therefore come to depend upon a considerably more advanced theoretical knowledge of our measuring instruments than we have yet mustered.'' \autocite[1231]{achen1975}
\end{quote}

\noindent I have argued that part of the toolkit of modern science fails in the presence of a particular, pervasive type of measurement concern. It is my hope that this essay constitutes an accurate philosophical diagnosis of the problem of reflexivity and lays a conceptual foundation for future solutions to this problem in the context of measurement.
